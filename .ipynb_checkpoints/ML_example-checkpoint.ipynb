{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Test\n",
    "Objective:   Train a classification models to make prediction on testing data set, using the data in the “Sequence model data.zip” file. \n",
    "\n",
    "Note: \n",
    "1.\tThis is a sequence classification task, where the order of each feature matters. You could train a model without considering order as a baseline model, but must train a model addressing sequence because in real work, sequence analysis is part of the project.\n",
    "1.\tEach row represents a training/testing sample containing a sequence, where the first element is “PPD_197” and last element is “PPD_0”.\n",
    "1.\tAll the sequences have been padding, which is the reason why lots of zeros show up in “PPD_0”. \n",
    "1.\tAll the values in each entry is categorical variable. Imaging every value in the entry as an index of a word in natural language. \n",
    "1.\tY-variable is the first column called “LABEL”, in testing data, there is no label\n",
    "\n",
    "What we expect,\n",
    "1.\tA good prediction result, which we will compare with the hold out y variable in the testing data set\n",
    "1.\tThe process of how the prediction is made, including \n",
    "  1. create new features based on existing variables could be needed. \n",
    "  1. feature analysis \n",
    "  1. feature selection \n",
    "  1. model comparison\n",
    "  1. hyper-parameter tuning\n",
    "1.\tIf you could use library such as Keras, Tensorflow to train a deep neural network (DNN) classifier, that will be a very good plus, even if neural networks might not be the best performed model. \n",
    "You could use any tools available to you for this task. Ultimately, we will assess your work based on two criteria. \n",
    "  1. predictive accuracy on the test set using the PR-AUC metric, \n",
    "  1. model structure you finally applied, for example, we will consider how advance the model is, or if you could create additional meaningful features from the data we gave to you.\n",
    "1. You should return to us the following:\n",
    "  1. A 23,910 x 1 csv or txt file containing one prediction per line for each row in the test dataset.\n",
    "  1. A brief report describing the techniques you used to obtain the predictions, that at least should include the following parts: \n",
    "    1. why do you choose the model you use? \n",
    "    1. your estimates of predictive performance on the test data set, \n",
    "    1. some words telling us your understanding about the model you use. \n",
    "    1. The code for building the model, or the saved model such as pickle file.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "Below is the plan that I intend to fulfill\n",
    "\n",
    "1. Split data into training and testing sets\n",
    "1. Explore basic summary stats\n",
    "1. Create a data set for all key predictors 1, 2 and 3 word combinations\n",
    "  1. Create dictionary of dictionaries to do it (function)\n",
    "  1. Remove in frequent combinations\n",
    "  1. Create pandas dataframe with all the good predictors (function)\n",
    "1. Perform feature selection to reduce to the key features\n",
    "  1. Get it down to 100 features\n",
    "1. Run 3 models and try to tune some parameters: \n",
    "  1. Logistic Regressions\n",
    "  1. Random forest\n",
    "  1. Support Vector machine\n",
    "1. Validate on the testing sets and test the one with the best outcome to ensure that it's not overfit\n",
    "1. Run the prediction on the lock box training set\n",
    "  1. Create a few summary stats on the prediction to ensure that mistakes weren't made\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "Set up the libraries needed for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T01:06:16.907005Z",
     "start_time": "2019-04-01T01:06:16.894004Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.fixes import signature\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Create functions that will be used throughout the data process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:40:10.085606Z",
     "start_time": "2019-04-01T00:40:10.078606Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_phrases(df):\n",
    "    \"\"\"Create unique phrases from the raw data\n",
    "\n",
    "    Args:\n",
    "        df(df): dataframe with an 'id' 'label' and n features\n",
    "        \n",
    "    Kwargs:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: 'id', 'label', 'comb' combined features\n",
    "    \"\"\"   \n",
    "    # Create a dataframe of combined features with id, label, and concatenated phrases of concatenated words\n",
    "    df_comb = pd.DataFrame(df[['id','label']])\n",
    "\n",
    "    #Create list of all columns to concatenate\n",
    "    cols = df.columns.values.tolist()\n",
    "    cols.remove('label')\n",
    "    cols.remove('id')\n",
    "\n",
    "    # Concatenate word to phrases and remove all zeros\n",
    "    df_comb['comb'] = df.loc[:, cols].apply(lambda x: '-'.join(x), axis=1)\n",
    "    df_comb['comb'].replace({'-0': ''}  ,inplace=True, regex=True)\n",
    "    df_comb['comb'].replace({'^[0]+-': ''},inplace=True, regex=True)\n",
    "    \n",
    "    return df_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## populate_phrase_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:40:10.107608Z",
     "start_time": "2019-04-01T00:40:10.087607Z"
    }
   },
   "outputs": [],
   "source": [
    "def populate_phrase_dict(df):\n",
    "    \"\"\"Create a dionary of phrases per id\n",
    "\n",
    "    Args:\n",
    "        df(df): dataframe with 'id','label', and n features\n",
    "        phrases: dionary of phrases to include\n",
    "        \n",
    "    Kwargs:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: 'id', 'label', 'comb' combined features\n",
    "    \"\"\"   \n",
    "    phrase_d = {} \n",
    "    phrase_cnt_d = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        #Identify all unique 2 and 3 word combinations per row\n",
    "        r2 = re.findall(r\"\\d+-\\d+\",row['comb'])\n",
    "        r3 = re.findall(r\"\\d+-\\d+-\\d+\",row['comb'])\n",
    "        r = r2+r3\n",
    "        r = list(set(r))\n",
    "\n",
    "        #Create a new key for the row id\n",
    "        phrase_d[row['id']] = {}\n",
    "\n",
    "        #Populate dionaries for unique phrases and phrase counts by id\n",
    "        for j in r:\n",
    "            phrase_d[row['id']][j] = 1\n",
    "            if j in phrase_cnt_d:\n",
    "                phrase_cnt_d[j] += 1\n",
    "            else:\n",
    "                phrase_cnt_d[j] = 1\n",
    "                \n",
    "    return phrase_d, phrase_cnt_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## populate_tidy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:40:10.122609Z",
     "start_time": "2019-04-01T00:40:10.110608Z"
    }
   },
   "outputs": [],
   "source": [
    "def populate_tidy_data(phrase_d, phrase_l, df_raw):\n",
    "    \"\"\"Populate final tidy data set with selected features\n",
    "\n",
    "    Args:\n",
    "        phrase_d(dict): dictionary of features per id\n",
    "        phrase_l(list): list of phrases to include\n",
    "        df(df): dataframe wtih 'id' and 'label'\n",
    "        \n",
    "    Kwargs:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        Dataframe: 'id', 'label', 'comb' combined features\n",
    "    \"\"\"   \n",
    "    phrase_df = pd.DataFrame(columns=phrase_l, dtype=bool)\n",
    "    \n",
    "    #Add id and label to the table\n",
    "    train_tidy = pd.concat([df_raw[['id','label']],phrase_df], axis=1)\n",
    "    train_tidy = train_tidy.fillna(0)\n",
    "\n",
    "    # Identify columns used in the process\n",
    "    columns = list(train_tidy[phrase_l].columns)\n",
    "\n",
    "    # Populate train_tidy with features from phrase_d\n",
    "    for index, row in train_tidy.iterrows():\n",
    "        for col in columns:\n",
    "            if col in phrase_d[row['id']]:\n",
    "                train_tidy.at[index,col] = 1\n",
    "                \n",
    "    return train_tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data\n",
    "Upload the raw data and create training and testing data sets\n",
    "\n",
    "**Output**\n",
    "* train_df: Training data set\n",
    "* test_df: Testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:40:13.940827Z",
     "start_time": "2019-04-01T00:40:10.125609Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create system variables from excel into script and review values in dictionary\n",
    "df = pd.read_csv('in/train.csv', dtype=str)\n",
    "df.columns = df.columns.str.lower()\n",
    "df['id'] = range(1, len(df) + 1)\n",
    "\n",
    "# Split into training and testing data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "#Drop df to save memory\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:40:13.950827Z",
     "start_time": "2019-04-01T00:40:13.942827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76635"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "19159"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm the training and testing is split 80:20\n",
    "len(train_df)\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:40:17.110008Z",
     "start_time": "2019-04-01T00:40:13.952828Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"out/train_df.pkl\")\n",
    "test_df.to_pickle(\"out/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy Training Data\n",
    "Create a tidy dataset where each column is a 1, 2 or 3 word phrase identified in the row that is above a certain count\n",
    "\n",
    "**Output**\n",
    "* train_tidy: Tidy data set with `id`, `label`, and ~1000 features to analyze\n",
    "* phrase_list: list of variables to include in the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create phrases\n",
    "Identify all permutations of 1, 2 and 3 word phrases in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:40:22.571321Z",
     "start_time": "2019-04-01T00:40:17.114008Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate all words into a single string\n",
    "df_comb = create_phrases(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:41:11.891141Z",
     "start_time": "2019-04-01T00:40:22.573321Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify all 2 and 3 word phrases\n",
    "(phrase_dict, phrase_cnt_dict) = populate_phrase_dict(df_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Thresholds\n",
    "Determine cut offs for frequency of phrases so that the future data frame so there is a resonable number of features.  The output of this is an empty dataframe with all of the phrases we are going to consider for the analysis.\n",
    "\n",
    "* All values that appeared at least 400 times were included as it created around 1000 features and was feasible to calcualte in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:41:12.139156Z",
     "start_time": "2019-04-01T00:41:11.893142Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataframe with counts of unique phrases per observation\n",
    "phrase_cnt_df = pd.DataFrame.from_dict(phrase_cnt_dict, orient='index')\n",
    "phrase_cnt_df.columns = ['cnt']\n",
    "phrase_cnt_df.cnt = pd.to_numeric(phrase_cnt_df.cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:42:10.747276Z",
     "start_time": "2019-04-01T00:42:10.733275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A minimum of at least 400 rows having a phrase cuts the list down to around 1000 predictors which is\n",
    "# reasonable given the computational resources for this exercise\n",
    "phrase_list = phrase_cnt_df[phrase_cnt_df['cnt']>400].index.tolist()\n",
    "len(phrase_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate Tidy Data\n",
    "Populate train_tidy with the following:\n",
    "* id and label from train_df\n",
    "* True if the feature existed for that observation\n",
    "* Limited to the ~1000 most popular phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:57:01.704098Z",
     "start_time": "2019-04-01T00:42:15.064405Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tidy=populate_tidy_data(phrase_dict, phrase_list, df_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Identify the top 200 features based by using a chi-squarred test.  The following [package](https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e) was used.\n",
    "\n",
    "**Output**\n",
    "* X_train: Training features\n",
    "* y_train: Training Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:57:06.119318Z",
     "start_time": "2019-04-01T00:57:01.708098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature       Score\n",
      "539    67-44  869.735421\n",
      "5       1-44  735.998174\n",
      "459     1-67  679.176229\n",
      "588    44-20  658.626661\n",
      "8       20-6  568.355100\n",
      "234      2-6  500.345558\n",
      "815     44-6  498.547558\n",
      "317      6-6  390.222095\n",
      "927  1-67-44  357.276328\n",
      "113      6-2  348.617116\n"
     ]
    }
   ],
   "source": [
    "#Create training df and outcome vector\n",
    "X = train_tidy[phrase_list]\n",
    "y_train = pd.to_numeric(train_tidy.label)\n",
    "\n",
    "#Use SelectKBest to get the top 200 features\n",
    "kBestFeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = kBestFeatures.fit(X,y_train)\n",
    "X_train = X[X.columns]\n",
    "\n",
    "#Review top 20 features for scores\n",
    "score_df = pd.DataFrame(fit.scores_)\n",
    "feature_df = pd.DataFrame(X.columns)\n",
    "feature_score_df = pd.concat([feature_df,score_df],axis=1)\n",
    "feature_score_df.columns = ['Feature','Score'] \n",
    "print(feature_score_df.nlargest(10,'Score')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy Testing Data\n",
    "Create the testing data set based on the data process to create the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:57:07.550400Z",
     "start_time": "2019-04-01T00:57:06.127319Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate all words into a single string\n",
    "test_comb_df = create_phrases(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T00:57:24.165344Z",
     "start_time": "2019-04-01T00:57:07.552400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify all 2 and 3 word phrases\n",
    "(test_phrase_dict, test_phrase_cnt_dict) = populate_phrase_dict(test_comb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T01:00:14.010568Z",
     "start_time": "2019-04-01T00:57:24.177344Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create final testing tidy data set\n",
    "test_tidy= populate_tidy_data(test_phrase_dict, phrase_list, test_comb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T01:00:14.156568Z",
     "start_time": "2019-04-01T01:00:14.010568Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create final data sets based on the variables we need\n",
    "X_test = test_tidy[X_train.columns]\n",
    "y_test = pd.to_numeric(test_tidy['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Data\n",
    "Pickle the training and testing data sets so they can be reloaded in the future, and it can clear as much memory as possible so that it is saved for the future model runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T01:04:27.395548Z",
     "start_time": "2019-04-01T01:04:22.295257Z"
    }
   },
   "outputs": [],
   "source": [
    "#Pickle Data\n",
    "X_train.to_pickle(\"out/X_train.pkl\")\n",
    "y_train.to_pickle(\"out/y_train.pkl\")\n",
    "X_test.to_pickle(\"out/X_test.pkl\")\n",
    "y_test.to_pickle(\"out/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T01:04:53.179881Z",
     "start_time": "2019-04-01T01:04:53.113878Z"
    }
   },
   "outputs": [],
   "source": [
    "del X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T01:06:52.921807Z",
     "start_time": "2019-04-01T01:06:51.948752Z"
    }
   },
   "outputs": [],
   "source": [
    "#Bring back in the data\n",
    "X_train = pd.read_pickle(\"out/X_train.pkl\")\n",
    "y_train = pd.read_pickle(\"out/y_train.pkl\")\n",
    "X_test  = pd.read_pickle(\"out/X_test.pkl\")\n",
    "y_test  = pd.read_pickle(\"out/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Linear\n",
    "Create a support vector machine model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "Train the Support Vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T01:07:16.686119Z",
     "start_time": "2019-04-01T01:06:54.858871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.48\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Machine Model\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_score = svm_model.decision_function(X_train)\n",
    "\n",
    "#Calculate PR-AUC\n",
    "average_precision = average_precision_score(y_train, y_score)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "Test the Support Vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T01:07:16.803125Z",
     "start_time": "2019-04-01T01:07:16.688119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.44\n"
     ]
    }
   ],
   "source": [
    "y_score = svm_model.decision_function(X_test)\n",
    "\n",
    "#Calculate PR-AUC\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Final Data\n",
    "Create the testing data set based on the data process to create the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all words into a single string\n",
    "final_comb_df = create_phrases(final_df)\n",
    "final_comb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all 2 and 3 word phrases\n",
    "(final_phrase_dict, final_phrase_cnt_dict) = populate_phrase_dict(final_comb_df)\n",
    "len(final_phrase_dict.keys())\n",
    "len(final_phrase_cnt_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final finaling tidy data set\n",
    "final_tidy= populate_tidy_data(final_phrase_dict, phrase_list, final_comb_df)\n",
    "final_tidy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final data sets based on the variables we need\n",
    "X_final = test_tidy[X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Stuff\n",
    "Other interesting code that was pushed to the back for reference later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T21:12:52.498187Z",
     "start_time": "2019-03-31T21:12:52.145167Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y, y_score)\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall', color='w')\n",
    "plt.ylabel('Precision', color='w')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-31T20:32:41.692189Z",
     "start_time": "2019-03-31T20:32:41.684188Z"
    }
   },
   "outputs": [],
   "source": [
    "# Frequency\n",
    "# stats_df = df_melt \\\n",
    "# .groupby('value') \\\n",
    "# ['value'] \\\n",
    "# .agg('count') \\\n",
    "# .pipe(pd.DataFrame) \\\n",
    "# .rename(columns = {'value': 'frequency'})\n",
    "# \n",
    "# stats_df = stats_df.sort_values('frequency', ascending=False)\n",
    "# \n",
    "# # PDF\n",
    "# stats_df['pdf'] = stats_df['frequency'] / sum(stats_df['frequency'])\n",
    "# \n",
    "# # CDF\n",
    "# stats_df['cdf'] = stats_df['pdf'].cumsum()\n",
    "# stats_df = stats_df.reset_index()\n",
    "# stats_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
